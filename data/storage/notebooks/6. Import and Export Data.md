# Import and export data

Data I/O is mission critical for any real-time data analysis platform. Deephaven supports a wide variety of data sources and formats, including [CSV](https://deephaven.io/core/docs/reference/cheat-sheets/csv/), [Parquet](https://deephaven.io/core/docs/reference/cheat-sheets/parquet/), [Kafka](https://deephaven.io/core/docs/reference/cheat-sheets/kafka/), and more. This notebook will cover those formats and more in Deephaven.

## CSV

Deephaven can [read CSV](https://deephaven.io/core/docs/how-to-guides/data-import-export/csv-import/) files that exist locally and remotely. This demo system does not have a network connection, so we'll read from a local CSV file:

```python
from deephaven import read_csv

iris = read_csv("/data/Iris/iris.csv")
```

It can also [write data to CSV](https://deephaven.io/core/docs/how-to-guides/data-import-export/csv-export/). The code below writes that same table back to a CSV file.

```python
from deephaven import write_csv

write_csv(iris, "/data/iris_new.csv")
```

Just to show that it's there:

```python
iris_new = read_csv("/data/iris_new.csv")
```

## Parquet

[Apache Parquet](https://deephaven.io/core/docs/how-to-guides/data-import-export/parquet-single/) is a columnar storage format that supports compression to store more data in less space. Deephaven supports [reading and writing single](https://deephaven.io/core/docs/how-to-guides/data-import-export/parquet-single/), [nested, and partitioned](https://deephaven.io/core/docs/how-to-guides/data-import-export/parquet-directory/) Parquet files. Parquet data can be stored locally or in [S3](https://deephaven.io/core/pydoc/code/deephaven.experimental.s3.html#module-deephaven.experimental.s3). The example below reads from a local Parquet file.

```python
from deephaven import parquet as dhpq

crypto_trades = dhpq.read("/data/Crypto/CryptoTrades_20210922.parquet")
```

That same table can be written back to a Parquet file:

```python
dhpq.write(crypto_trades, "/data/crypto_trades_new.parquet")
```

Just to show that it worked:

```python
crypto_trades_new = dhpq.read("/data/crypto_trades_new.parquet")
```

## Kafka

[Apache Kafka](https://deephaven.io/core/docs/how-to-guides/data-import-export/kafka-stream/) is a distributed event streaming platform that can be used to publish and subscribe to streams of records. Deephaven can consume and publish to Kafka streams. This demo system has access to a Kafka system. The code below consumes a stream.

```python
from deephaven import kafka_consumer as ck
from deephaven.stream.kafka.consumer import TableType, KeyValueSpec


trades_stream = ck.consume(
    {
        'bootstrap.servers' : 'redpanda.kafka.svc.cluster.local.:9093',
        'schema.registry.url' : 'http://redpanda.kafka.svc.cluster.local.:8081'
    },
    'io.deephaven.crypto.kafka.TradesTopic',
    key_spec=KeyValueSpec.IGNORE,
    value_spec = ck.avro_spec('io.deephaven.crypto.kafka.TradesTopic-io.deephaven.crypto.Trade'),
    offsets=ck.ALL_PARTITIONS_SEEK_TO_END,
    table_type=TableType.append()
)
```

Writing to Kafka is done similarly, but is outside the scope of this demo. See [Kafka in Deephaven](https://deephaven.io/core/docs/conceptual/kafka-in-deephaven/) for more information on Kafka.

## Function generated tables

[Function generated tables](https://deephaven.io/core/docs/how-to-guides/function-generated-tables/) are tables populated by a Python function.  The function is reevaluated when source tables change or at a regular interval.  The following example re-generates data in a table once per second.

```python
from deephaven import empty_table, function_generated_table


def regenerate():
    return empty_table(10).update(
        [
            "Group = randomInt(1, 4)",
            "GroupMean = Group == 1 ? -10.0 : Group == 2 ? 0.0 : Group == 3 ? 10.0 : NULL_DOUBLE",
            "GroupStd = Group == 1 ? 2.5 : Group == 2 ? 0.5 : Group == 3 ? 1.0 : NULL_DOUBLE",
            "X = randomGaussian(GroupMean, GroupStd)",
        ]
    )


fgt = function_generated_table(table_generator=regenerate, refresh_interval_ms=1000)
```

[Function generated tables](https://deephaven.io/core/docs/how-to-guides/function-generated-tables/), on their own, don't do any data I/O. However, Python functions evaluated at a regular interval to create a ticking table are a powerful for data ingestion from external sources like WebSockets, databases, and much more. Check out this [blog post](https://deephaven.io/blog/2023/10/06/function-generated-tables/#what-is-a-function-generated-table) that uses WebSockets to stream data into Deephaven with function generated tables.

## Where to go from here

This wraps up the Deephaven crash course. In it, you learned about:

- Deephaven's basic architecture
- Table constructors
- Table operations
- Query strings
- Python integrations
- Plotting
- Data I/O

This crash course has condensed what we believe to be the fundamental concepts required to become a powerful Deephaven developer. To continue learning more about Deephaven, check out any of these links:

- [Deephaven's design](https://deephaven.io/core/docs/conceptual/technical-building-blocks/)
- [Incremental update model](https://deephaven.io/core/docs/conceptual/table-update-model/)
- [Live DAG](https://deephaven.io/core/docs/conceptual/dag/)
- [Table listeners](https://deephaven.io/core/docs/how-to-guides/table-listeners-python/)
- [Replay](https://deephaven.io/core/docs/how-to-guides/replay-data/)
- [Execute SQL queries in Deephaven](https://deephaven.io/core/docs/how-to-guides/data-import-export/execute-sql-queries/)
- [Access table metadata](https://deephaven.io/core/docs/how-to-guides/metadata/)
- [Select and create columns](https://deephaven.io/core/docs/how-to-guides/use-select-view-update/)
- [Filter table data](https://deephaven.io/core/docs/how-to-guides/use-filters/)
- [Multiple aggregations](https://deephaven.io/core/docs/how-to-guides/combined-aggregations/)
- [Group and ungroup data](https://deephaven.io/core/docs/how-to-guides/grouping-data/)
- [update_by](https://deephaven.io/core/docs/how-to-guides/use-update-by/)
- [Exact and relational joins](https://deephaven.io/core/docs/how-to-guides/joins-exact-relational/)
- [Inexact, time-series, and range joins](https://deephaven.io/core/docs/how-to-guides/joins-timeseries-range/)
- [Create and use partitioned tables](https://deephaven.io/core/docs/how-to-guides/partitioned-tables/)
- [Capture table history with snapshots](https://deephaven.io/core/docs/how-to-guides/capture-table-history/)
- [Work with time](https://deephaven.io/core/docs/conceptual/time-in-deephaven/)
- [User-defined functions](https://deephaven.io/core/docs/how-to-guides/user-defined-functions/)
- [Programmatically generate query strings](https://deephaven.io/core/docs/how-to-guides/generate-query-strings/)
- [Deephaven's Python package](https://deephaven.io/core/docs/how-to-guides/deephaven-python-package/)
- [Jupyter](https://deephaven.io/core/docs/how-to-guides/jupyter/)
- [Plotting](https://deephaven.io/core/docs/how-to-guides/plotting/)
- [Python server API documentation]( https://deephaven.io/core/pydoc)

Join our [Community Slack](https://deephaven.io/slack) for help with your queries, news about releases and features, and more!
